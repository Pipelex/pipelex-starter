################################################################################
# Pipelex Gateway Configuration
################################################################################
#
# This file defines the model specifications for the Pipelex Gateway backend.
# It contains model definitions for various AI models:
# LLMs of course but also image generation models and document extraction models.
#
# Configuration structure:
# - Each model is defined in its own section with the model name as the header
# - Headers with dots must be quoted (e.g., ["gpt-4.1"])
# - Model costs are in USD per million tokens (input/output)
#
# Documentation: https://docs.pipelex.com
# Support: https://go.pipelex.com/discord
#
################################################################################

################################################################################
# MODEL DEFAULTS
################################################################################

[defaults]
model_type = "llm"
sdk = "gateway_completions"
structure_method = "instructor/openai_tools"
prompting_target = "anthropic"

################################################################################
# LANGUAGE MODELS
################################################################################

# --- OpenAI LLMs --------------------------------------------------------------
[gpt-4o-mini]
model_id = "gpt-4o-mini-2024-07-18"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.15, output = 0.6 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[gpt-4o]
model_id = "gpt-4o-2024-11-20"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 2.5, output = 10.0 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-4.1-nano"]
model_id = "gpt-4.1-nano-2025-04-14"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.1, output = 0.4 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-4.1-mini"]
model_id = "gpt-4.1-mini-2025-04-14"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.4, output = 1.6 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-4.1"]
model_id = "gpt-4.1-2025-04-14"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 2, output = 8 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[o1-mini]
model_id = "o1-mini-2024-09-12"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 3.0, output = 12.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[o1]
model_id = "o1-2024-12-17"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 15.0, output = 60.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[o3-mini]
model_id = "o3-mini-2025-01-31"
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 1.1, output = 4.4 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[o3]
model_id = "o3-2025-04-16"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 2, output = 8 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[o4-mini]
model_id = "o4-mini-2025-04-16"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.1, output = 4.4 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[gpt-5-nano]
model_id = "gpt-5-nano-2025-08-07"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.05, output = 0.4 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[gpt-5-mini]
model_id = "gpt-5-mini-2025-08-07"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.25, output = 2.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[gpt-5-chat]
model_id = "gpt-5-chat-2025-08-07"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.25, output = 10.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

[gpt-5]
model_id = "gpt-5-2025-08-07"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.25, output = 10.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-5.1-chat"]
model_id = "gpt-5.1-chat-2025-11-13"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.25, output = 10.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-5.1"]
model_id = "gpt-5.1-2025-11-13"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.25, output = 10.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

["gpt-5.1-codex"]
model_id = "gpt-5.1-codex-2025-11-13"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 1.25, output = 10.0 }
valued_constraints = { fixed_temperature = 1 }
sdk = "gateway_responses"
structure_method = "instructor/openai_responses_tools"
x-portkey-config = "pc-openai-ba0fa7"

# --- OpenAI GPT-OSS Models ----------------------------------------------------
["gpt-oss-20b"]
model_id = "openai.gpt-oss-20b-1:0"
max_tokens = 65536
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 0.075, output = 0.30 }
x-portkey-config = "pc-gptoss-fb48b7"

["gpt-oss-120b"]
model_id = "openai.gpt-oss-120b-1:0"
max_tokens = 65536
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 0.15, output = 0.60 }
x-portkey-config = "pc-gptoss-fb48b7"

# --- Claude LLMs --------------------------------------------------------------

["claude-3.7-sonnet"]
model_id = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
max_tokens = 64000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 3.0, output = 15.0 }
x-portkey-config = "pc-claude-aae09f"

[claude-4-sonnet]
model_id = "us.anthropic.claude-sonnet-4-20250514-v1:0"
max_tokens = 64000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 3.0, output = 15.0 }
x-portkey-config = "pc-claude-aae09f"

[claude-4-opus]
model_id = "us.anthropic.claude-opus-4-20250514-v1:0"
max_tokens = 32000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 3.0, output = 15.0 }
x-portkey-config = "pc-claude-aae09f"

["claude-4.1-opus"]
model_id = "us.anthropic.claude-opus-4-1-20250805-v1:0"
max_tokens = 32000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 3.0, output = 15.0 }
x-portkey-config = "pc-claude-aae09f"

["claude-4.5-sonnet"]
model_id = "us.anthropic.claude-sonnet-4-5-20250929-v1:0"
max_tokens = 64000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 3.0, output = 15.0 }
x-portkey-config = "pc-claude-aae09f"

["claude-4.5-haiku"]
model_id = "us.anthropic.claude-haiku-4-5-20251001-v1:0"
max_tokens = 64000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 1.0, output = 5.0 }
x-portkey-config = "pc-claude-aae09f"

["claude-4.5-opus"]
model_id = "global.anthropic.claude-opus-4-5-20251101-v1:0"
max_tokens = 64000
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 100
costs = { input = 5.0, output = 25.0 }
x-portkey-config = "pc-claude-aae09f"

# --- DeepSeek LLMs --------------------------------------------------------------
# [deepseek-r1]
# model_id = "deepseek.r1-v1:0"
# inputs = ["text", "images"]
# outputs = ["text", "structured"]
# costs = { input = 0, output = 0 }
# structure_method = "instructor/json"
# x-portkey-config = "pc-bedroc-96f922"

["deepseek-v3.1"]
model_id = "deepseek.v3-v1:0"
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 0, output = 0 }
structure_method = "instructor/json"
x-portkey-config = "pc-bedroc-96f922"

# --- Gemini LLMs --------------------------------------------------------------
["gemini-2.0-flash"]
model_id = "gemini-2.0-flash"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.10, output = 0.40 }
x-portkey-config = "pc-google-b19ef8"

["gemini-2.5-pro"]
model_id = "gemini-2.5-pro"
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 3000
costs = { input = 1.25, output = 10.0 }
x-portkey-config = "pc-google-b19ef8"

["gemini-2.5-flash"]
model_id = "gemini-2.5-flash"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.30, output = 2.50 }
x-portkey-config = "pc-google-b19ef8"

["gemini-2.5-flash-lite"]
model_id = "gemini-2.5-flash-lite"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0.10, output = 0.40 }
x-portkey-config = "pc-google-b19ef8"

["gemini-3.0-pro"]
model_id = "gemini-3-pro-preview"
inputs = ["text", "images"]
outputs = ["text", "structured"]
max_prompt_images = 3000
costs = { input = 2, output = 12.0 }
x-portkey-config = "pc-google-b19ef8"

# --- Qwen LLMs --------------------------------------------------------------
["qwen3-vl-235b-a22b"]
model_id = "qwen.qwen3-vl-235b-a22b"
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 0, output = 0 }
structure_method = "instructor/json"
x-portkey-config = "pc-bedroc-96f922"

# --- XAI LLMs --------------------------------------------------------------

[grok-3]
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 3, output = 15 }
x-portkey-config = "pc-azure-551745"

[grok-3-mini]
inputs = ["text"]
outputs = ["text", "structured"]
costs = { input = 0.3, output = 0.5 }
x-portkey-config = "pc-azure-551745"

# [grok-4]
# inputs = ["text", "images"]
# outputs = ["text", "structured"]
# costs = { input = 3, output = 15 }
# x-portkey-config = "pc-azure-551745"

# [grok-4-fast-reasoning]
# inputs = ["text", "images"]
# outputs = ["text", "structured"]
# costs = { input = 3, output = 15 }
# x-portkey-config = "pc-azure-551745"

[grok-4-fast-non-reasoning]
inputs = ["text", "images"]
outputs = ["text", "structured"]
costs = { input = 3, output = 15 }
x-portkey-config = "pc-xai-70a222"

################################################################################
# DOCUMENT EXTRACTION MODELS
################################################################################

[mistral-ocr]
# "mistral-document-ai-2505" provides the same capabilities as "mistral-ocr" and more but currently we use it like "mistral-ocr"
model_id = "mistral-document-ai-2505"
model_type = "text_extractor"
max_tokens = 4096
inputs = ["pdf", "image"]
outputs = ["pages"]
costs = { input = 0, output = 0 }     # TODO handle cost per page 3$/1K pages
sdk = "gateway_extract"
x-portkey-config = "pc-misdoc-b4ae47"


################################################################################
# IMAGE GENERATION MODELS
################################################################################

# We are still working in giving you acces to image generation models
# through the Pipelex Gateway.
